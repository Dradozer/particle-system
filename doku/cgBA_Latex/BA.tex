\documentclass[intern,palatino]{cgBA}

\author{Sebastian Gaida}
\title{Simulation von Rauch}
\zweitgutachter{Bastian Krayer MSc. }
\zweitgutachterInfo{(Institut für Computervisualistik, AG Computervisualistik)}
\externLogo{7.46cm}{logos/UniLogoNeu}
\externName{DIN: NewTechnologies}

\sloppy

\usepackage{acronym}
\usepackage{hyperref}
\usepackage{url}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{pgfplots}
\usepackage{subfigure}
\pgfplotsset{compat=1.16 ,legend style={at={(0.02,.98)},anchor=north west}}

\lstset{language=C++,
	frame=tb,
	tabsize=4,
	showstringspaces=false,
	numbers=left,
	commentstyle=\color{olive},
	keywordstyle=\color{blue},
	stringstyle=\color{red}
}

\setcounter{secnumdepth}{4}

\begin{document}

	\maketitle
	\newpage
	\pagenumbering{roman}
	\tableofcontents
	\clearpage         % oder \cleardoublepage bei zweiseitigem Druck
	% \listoffigures   % fuer ein eventuelles Abbildungsverzeichnis
	\pagenumbering{arabic}
	\bibliographystyle{alphadin}

%-------------------------------------------------------------------------------

\section*{Abstract}\label{abstract}

In dieser Arbeit wird auf die realistische Simulation von Rauch eingegangen. Dabei bezieht sich die Arbeit hauptsächlich auf die Simulationen von Müller et al.\cite{muller2003particle} und Ren et al.\cite{ren2016fast}. Die Simulation wurde mittels C++, der OpenGL und Compute-Shadern erstellt. Hierbei wurde das SPH-Verfahren genutzt und die Möglichkeiten zur Beschleunigung auf der GPU untersucht.
\newline \newline
This paper deals with the realistic simulation of smoke. The work refers mainly to the simulations of Müller et al.\cite{muller2003particle} and Ren et al.\cite{ren2016fast}. The simulation was created using C++, the OpenGL and compute shaders. Here the SPH method was used and the possibilities to accelerate it on the GPU were investigated.
\newpage

%-------------------------------------------------------------------------------

\section{Vorwort}\label{vorwort}

Vor dem Beginn der vorliegenden Bachelorarbeit möchte ich mich zunächst bei einigen Personen bedanken die mich während der Arbeit unterstützt haben.
\newline \newline
Zunächst einmal bedanke ich mich bei Prof. Dr.-Ing. Stefan Müller und Bastian Krayer MSc. für die großartige Betreuung meiner Arbeit.
\newline
Außerdem möchte ich mich bei Pascal Bendler bedanken, der mich tatkräftig beim debugging unterstützt hat.
\newline
Ein großes Dankeschön geht auch an den Freund, der mich immer wieder dazu motiviert hat weiter zu arbeiten und nach alternativen Möglichkeiten zu suchen.
\newpage

%-------------------------------------------------------------------------------

\section{Einleitung}\label{einleitung}

Das Ziel dieser Arbeit ist es eine möglichst physikalisch korrekte Rauchsimulation zu implementieren. Dazu nutzen wir, dass sich Rauch wie ein Fluid verhält \cite{stam2003real}, dabei wird die Simulation der physikalischen Basis von Fluiden angenähert. Hierbei wird in dieser Implementation ein Partikelsystem zur Berechnung der physikalischen Eigenschaften genutzt. Echtzeitanwendungen wie die Unity-Engine bieten eine Partikelsimulation an, jedoch beschränkt sich diese lediglich auf das Ausstoßen von Partikeln. Dabei können Partikelinteraktionen, sowie Verhaltensmuster nicht bearbeitet werden.
\newline \newline
Die GPU eignet sich besonders gut zum berechnen parallelisierbarer Rechenoperationen, da sie im Vergleich zur CPU, die nur wenige Kerne besitzt, über tausend Kerne verfügt, die zwar nicht so leistungsfähig sind wie die der CPU, aber dennoch einen signifikante Steigerung der Leistung bieten.
\newline \newline
In der Arbeit wird auch darauf eingegangen den genannten Aufwand zu minimieren, dazu wurden zwei Verfahren zur Beschleunigung des Partikelsystems, auf der GPU,  implementiert und gegenübergestellt.
\newline \newline
Für die Implementation wurde OpenGL genutzt, welches das programmieren auf der GPU deutlich vereinfacht und seit der Version 4.3 auch das verarbeiten von Daten mit Hilfe von Compute-Shadern unterstützt. Für den schnellstmöglichen Zugriff auf diese Daten wird Speicherplatz, in Form von SSBO, auf derGPU angelegt. Dabei sollte auch auf eine effiziente Nutzung des limitierten Speicherplatzes geachtet werden.

%-------------------------------------------------------------------------------

\section{State of the Art}\label{state}
Die Simulation von einem Systemen, zur Darstellung von Fluiden, ist ein jahrelange Herausforderung für die Computergrafik. Dabei treten immer wieder die gleichen Problemstellungen auf. Zum einen soll die Simulation physikalisch korrekt sein, um eine für den Beobachter ein möglichst schönes, sowie nachvollziehbarer Ergebnis zu bieten. Schon kleinstes Fehlverhalten können die Immersion zerstören. Andererseits soll das System auch in Echtzeit berechnet werden und dabei auf mögliche Interaktionen reagieren können. Für eine möglichst effiziente Berechnung werden verschiedene Beschleunigungsverfahren verwendet, die ein gutes Ressourcenmanagement in Form der Laufzeit sowie Speicherplatz erfordern.
\newline \newline
Die physikalische Grundlage, die Navier-Stokes-Gleichungen, basiert dabei auf den Gleichungen die von Claude Louis Marie Henri Navier und George Gabriel Stokes im 19. Jahrhundert aufgestellt wurden \cite{wiki:xxx}. Diese Gleichungen beschreiben die physikalischen Eigenschaften von Fluiden und werden für die Simulation dieser angewendet. Diese Formeln werden je nach Fluid noch angepasst um speziellere Eigenschaften darzustellen.
\newline
Diese Simulation wird meist in Form eines rasterbasierenden Verfahren oder eines Partikelsystems implementiert.\newline

%-------------------------------------------------------------------------------

\subsection{Vektorfeldverfahren}\label{vektor}
Beim Vektorfeldverfahren wird die Umgebung in gleichgroße Voxels unterteilt, auch bekannt als Voxelgrid oder eulersches Grid. Bei diesem Vektorfeldverfahren betrachtet man die Partikel nicht direkt sondern einen Masse die in Form des Voxels generalisiert wird. Dabei werden Parameter wie Dichte, Druck und Geschwindigkeit in dem jeweiligen Voxel gespeichert. Die Berechnungen lassen sich in Advektion, Druck, Diffusion und Beschleunigung unterteilen. Die Advektion beschreibt dabei den Strömungstransport, das Übertragen der Bewegungskraft auf ein anliegendes Objekt. Druck wiederum beschreibt die Übertragung von Kräften an benachbarte Partikel, wodurch bei einem zu hohen Druck eine Kraft vom Zentrum weg entsteht und wiederum bei einem Unterdruck eine Kraft zum Zentrum hin. Die Diffusion beschreibt die Viskosität des Fluides. Je nach Anpassung der breitet sich das Fluid stark aus wie zum Beispiel Wasser oder weniger stark wie Lava aus.
Bei Beschleunigung handelt es sich um externe Kräfte die auf das Fluid einwirken, dies ist vergleichbar mit der Schwerkraft oder einer Windgeschwindigkeit. Zur Beschleunigung zählt man bei den Vektorfeldern aber auch die Wirbelkraft, die bei Rauch die typischen Turbulenzen verursacht und damit einen signifikanten Einfluss auf die Erscheinung hat.
\newline
Wegen der physikalisch präziseren Ergebnisse eignet sich diese Verfahren besonders für Strömungsimulationen in Innenräumen \cite{franz}, da man Kraft dem System zuführt, diese Kraft wird daraufhin eingefärbt und spiegelt dabei das Fluid wieder.
\newline
Bei dieser Methode stellt das Lösen der Gleichungen und die Visualisierung der Ergebnisse die größte Schwierigkeit da. Die Visualisierung erweist sich als Hindernis, da in jedem Voxel Kräfte vorhanden sind. Dabei unterscheidet man in dem Grid unter einem gefärbten Teil und einem nicht sichtbaren Teil der meist Luft repräsentiert \ref{img:Vertexfeld}. Zur Darstellung des Fluides wird meist Volumerendering genutzt. Außerdem ist, wegen der Grid-Architektur des Verfahrens, der Rechenaufwand hoch und lässt sich nur schwer verbessern.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\columnwidth]{Bilder/vektorfeld.jpg}
	\caption[Fluidsimulation in Form des Vektorfeldverfahren \newline Quelle:\url{https://thumbs.gfycat.com/CelebratedElasticHartebeest-poster.jpg}]{Fluidsimulation in Form des Vektorfeldverfahren}
	\label{img:Vertexfeld}
\end{figure}

%-------------------------------------------------------------------------------

\subsection{Partikelsystem}\label{partikel}

Bei dem Verfahren einer Partikelsimulation werden die Partikel einzeln betrachtet, dies bezeichnet man auch lagrangiansches Verfahren. Diese speichern Parameter wie Position und Geschwindigkeit selber ab. Die Berechnungen beschränken sich dabei auf die Dichte, Druck, Viskosität, Auftrieb und Wirbelkraft.
Bei den Berechnungen werden die Nachbarpartikel mit einbezogen. Die Dichte beschreibt dabei wie viele Nachbarpartikel Einfluss auf dieses bestimmte Partikel haben und wird als Gewichtung für die Berechnung der Kräfte verwendet. Das typische Verhalten des Fluides, wird aber durch das Zusammenspiel der Kräfte Drucke und Viskosität erzeugt. Dabei sorgt der Druck dafür, dass Partikel sich voneinander wegbewegen und die Viskosität wirkt dem entgegen und führt das Anziehen von Partikel hervor. Der Auftrieb wiederum lässt sich über die Temperatur des Rauches bestimmen, welche je nach Dichte steigt oder sinkt. Zum anderen lässt sich aber die Wirbelkraft nicht so einfach berechnen und stellen somit ein Problem in der Forschung dar.
Für die Berechnungen werden die Nachbarpartikel benötigt, welche aber nicht für jeden Partikel bekannt sind und es entsteht ein großer Aufwand, wenn man aus Einfachheit alle Partikel mit einbezieht. Hierbei entstehen viele Möglichkeiten das System zu beschleunigen.
\newline
Der Ansatz eines Partikelsystems eignet sich hervorragen zum einbinden in eine Echtzeitanwendung, wie ein Computerspiel oder einer Engine, da man mit der Partikelanzahl  die Performance beeinflussen kann. Beim Reduzieren der Partikel sollte eine Anpassung der Parameter erfolgen, da dies sonst einen signifikanten Einfluss auf das Verhalten des Fluides hat.
\newline
Die größten Schwierigkeiten bei einer Rauchsimulation in Form eines Partikelsystems entstehen durch Beschleunigung der Nachbarschaftssuche, sowie den Auftrieb und die Wirbelkraft.
\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\columnwidth]{Bilder/partikelsystem.jpg}
	\caption[Partikelsimulation von Wasser \newline \url{https://i.ytimg.com/vi/DhNt_A3k4B4/maxresdefault.jpg}]{Partikelsimulation von Wasser}
	\label{img:Partikelsystem}
\end{figure}

%-------------------------------------------------------------------------------

\section{Rauchsimulation}\label{rauch}

% Längeren Text
Zur Simulation von Rauch wurde ein Partikelsystem implementiert, wessen physikalische Grundlage auf dem SPH-Verfahren basiert, welches Müller \cite{muller2003particle} 2003 zur Simulation von Fluiden genutzt hat. Dabei handelt es sich um eine Abwandelung der Navier-Stokes-Gleichungen für die Berechnung der Dichte, Druckes und Viskosität. Diese wurden zur Verwendung in einem SPH angepasst. Der Auftrieb, sowie die Temperaturberechung, stammen aus einem Paper von Ren \cite{ren2016fast}. Die größten Probleme bei der Implementation bereitete aber die Wirbelkraft, Ren und Macklin \cite{macklin2014unified} boten eine Formel zur Berechnung dar, welche aber nicht das gewünschte Ergebnis lieferte.
\newline
Die Berechnung der Simulation bedarf vieler Schritte die von einander abhängig sind. In Abbildung  \ref{code:sim} werden alle Rechenschritte in einen optimalen Reihenfolge dargestellt. Die Berechnungen lassen sich in 4 Compute-Shader unterteilen.
\newline
Zum Verständnis bildet Abbildung \ref{tab:Symbole} alle Variablen da, sowie deren Bedeutung und Format.

\begin{figure}
	\centering
	\begin{lstlisting}
computeshader 1	
	for all particle i do
		for all neighbor of i do
			calculate density
		end for
		calculate pressure
	end for
end computeshader 1
computeshader 2
	for all particle i do
		for all neighbor of i do
			calculare normal
		end for
		calculate vorticity
	end for
end computeshader 2
computeshader 3
	for all particle i do
		for all neighbor of i do
			calculate pressure force
			calculate viscosity force
			calculate vorticity force
			calculate temperature
		end for
		calculate temperature cooldown
		calculate buoyancy force
		update velocity
	end for
end computeshader 3
computeshader 4
	for all particle i do
		apply velocity on position
	end for
end computeshader 4
	\end{lstlisting}
	\caption{Updateschleife der Physik}
	\label{code:sim}
\end{figure}

\begin{figure}
	\centering
		\begin{tabular}{ | c | p{8cm} | c |}
			\hline
			Symbol & Bedeutung & Format  \\ \hline
			$m_i $ 				&  Masse des Partikel i								&	float	\\ \hline
			$r_i $		 		&  Position des Partikel i							&	vec3	\\ \hline
			$r_{ij}$ 			&  Abstandsvektor von $r_i - r_j$					&	vec3	\\ \hline
			$v_i$	 			&  Geschwindigkeitsvektor des Partikel i			&	vec3	\\ \hline
			$h $ 				&  Radius											&	float	\\ \hline
			$W_{ij} $ 			&  Gewichtungsfunktion, kurz für $W (r_i - r_j)$	&	float	\\ \hline
			$\nabla W_{ij} $ 	&  Gradienten-Gewichtungsfunktion					&	vec3	\\ \hline
			$\nabla^2 W_{ij} $ 	&  Laplace-Gewichtungsfunktion						&	float	\\ \hline
			$\rho_i $ 			&  Dichte des Partikel i		 					&	float	\\ \hline
			$\rho_0 $ 			&  Ruhedichte im Allgemeinen						&	float	\\ \hline
			$k $ 				&  Steifheit des Fluides							&	float	\\ \hline
			$p_i $ 				&  Druck des Partikel i								&	float	\\ \hline
			$f^{pressure}_i $	&  Druckkraft des Partikel i						&	vec3	\\ \hline
			$\mu $ 				&  Viskosität des Fluides							&	float	\\ \hline
			$\nu_i $ 			&  Viskosität des Partikel i						&	float	\\ \hline
			$f^{viscosity}_i $ 	&  Viskositätskraft des Partikel i					&	vec3	\\ \hline
			$T_i $ 				&  Temperatur des Partikel i						&	float	\\ \hline
			$D_r $ 				&  Zeit zum halbieren der Temperatur				&	float	\\ \hline
			$b $ 				&  Up-Vektor										&	vec3	\\ \hline
			$D_c $ 				&  Wärmeleitfähigkeitsfunktion des Fluides			&	float	\\ \hline
			$c $ 				&  Wärmeleitfähigkeit								&	float	\\ \hline
			$C_b $ 				&  Auftriebs-Koeffizient							&	float	\\ \hline
			$a_{b,i} $ 	  		&  Auftriebsbeschleunigung							&	vec3	\\ \hline
			$n_i $ 				&  Normale des Partikel i							&	vec3	\\ \hline
			$C_N $ 				&  nutzerdefinierter Schwellenwert					&	float	\\ \hline
			$y $ 				&  Zahl die nahezu 0 ist					 		&	float	\\ \hline
			$f^{buoyancy}_i $ 	&  Auftriebskraft des Partikel i					&	vec3	\\ \hline
			$\beta $ 			&  nutzerdefinierter Wert							&	float	\\ \hline
			$\omega_i $ 		&  Wirbelstärke des Partikel i						&	vec3	\\ \hline
			$f^{vortex}_i $ 	&  Wirbelkraft des Partikel i						&	vec3	\\ \hline
			$g $ 				&  Gravitationskraft								&	vec3	\\ \hline
			$ext $ 				&  externe Kraft									&	vec3	\\ \hline
			$\delta t $ 		&  Zeit seit letzter Iteration 						&	float	\\ \hline
			$\delta $ 			&  veränderte Wert im Abstand von $\delta t$ 		&			\\
			\hline
		\end{tabular}
	\caption{Bedeutung aller Symbole der Berechnungen}
	\label{tab:Symbole}
\end{figure}

%-------------------------------------------------------------------------------

\subsection{Gewichtungsfunktionen}\label{kernel}

Ein wichtiger Aspekt welchen Einfluss Nachbarpartikel auf den betrachteten Partikel haben sind die Gewichtungsfunktionen. Diese bestimmen den Einfluss über die Entfernung $r_{ij}$ der Partikel zu einander, dabei spielt der Radius als Maximalabstand eine wichtige Rolle. Die Funktionen besitzen alle die Eigenschaft, dass sie symmetrisch sind und beim erreichen des Radius gegen 0 konvergieren und damit haben weit entfernte Partikel keinen Einfluss mehr. Gewichtungsfunktionen dienen dazu um eine Stabilität in das Partikelsystem zu bringen. Dabei nähern sie sich üblich Ableitungen von bestimmten Funktionen an \cite{muller2003particle}. Diese Funktionen wurden mit Hilfe von Bastian Krayer implementiert.
\newline
Für das SPH werden die drei folgenden Gewichtungsfunktionen genutzt. Abhängig von den Berechnungen wird eine andere Funktion für die richtige Stabilität des Systems benötigt. In Abbildung \ref{img:kernel} ist der Verlauf der Funktionen dargestellt.
\newline
Die $W_{poly}$-Funktion \ref{funk:normal} bietet einen weichen abfallenden Verlauf bei ansteigendem Abstand, diese Funktion wird als Standard für jegliche Berechnung genutzt.
\newline
Es werden aber für die Berechnungen ebenfalls ein Gradient, sowie der Laplace benötigt. Der Gradient für die Druckberechnung lässt sich durch die Ableitung der für diese Berechnung vorgesehene Funktion berechnen. Mit der $W_poly$-Funktion beim Wert 1, bei der die Druckkraft am höchsten sein sollte, ein nahezu 0 Wert erreicht, welcher dazu führen würde, dass sehr nahe Partikel sich nicht mehr abstoßen würden. Deshalb nutzt Müller Desbrun \cite{desbrun1996smoothed} Funktion \ref{funk:gradient}, da diese in der Ableitung \ref{funk:gradient2} Werte liefert, die für die Berechnung entsprechend konvergieren.
\newline\newline

\begin{equation}\label{funk:normal}
	W_{poly6}(r_{i,j}) = \frac{315}{64 \pi h^9}   
	\begin{cases}
	(h^2 - r^2)^3 		& 0	\leq r \leq h	\\
	0					& otherwise			\\
	\end{cases}
\end{equation}

\begin{equation}\label{funk:gradient}
W_{spiky}(r_{i,j}) = \frac{15}{\pi h^6}   
\begin{cases}
(h - r)^3 		& 0	\leq r \leq h	\\
0					& otherwise			\\
\end{cases}
\end{equation}

\begin{equation}\label{funk:gradient2}
\nabla W_{spiky}(r_{i,j}) = \frac{-45}{\pi h^6}   
\begin{cases}
(h - r)^2 		& 0	\leq r \leq h	\\
0					& otherwise			\\
\end{cases}
\end{equation}

\begin{equation}\label{funk:laplace}
W_{visc}(r_{i,j}) = \frac{15}{2 \pi h^3}   
\begin{cases}
-\frac{r^3}{2h^3} + \frac{r^2}{h^2} + \frac{h}{2r} -1  		& 0	\leq r \leq h	\\
0					& otherwise			\\
\end{cases}
\end{equation}

\begin{equation}\label{funk:laplace2}
\nabla ^2 W_{visc}(r_{i,j}) = \frac{45}{\pi h^6}
\begin{cases}
(h-r) 		& 0	\leq r \leq h	\\
0					& otherwise			\\
\end{cases}
\end{equation}

\newpage

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\columnwidth]{Bilder/kernel.jpg}
	\caption{Die Gewichtungsfunktionen $W_{poly6}$, $W_{spiky}$, $W_{visc}$ nach \cite{muller2003particle} mit einem Radius von 1}
	\label{img:kernel}
\end{figure}
Die $W_{spiky}$-Funktion, würde aber wiederum in der zweiten Ableitung 0 werden, bei anderen standardmäßigen Gewichtungsfunktionen könnte es sogar dazu führen, dass ein negativer Wert auftritt, der bei der Viskosität einen gegensätzlichen dem gewünschtem Effekt hätte. Deshalb wurde die $W_{visc}$-Funktion \ref{funk:laplace} entworfen, dessen Laplace \ref{funk:laplace2} optimal für die Berechnung der Viskosität ist.

\begin{figure}[H]
	\centering
	\includegraphics[width=1.35\columnwidth]{Bilder/impKernel.jpg}
	\caption{Implementation der SPH Kernel}
	\label{img:impkernel}
\end{figure}

In Abbildung \ref{img:impkernel} sind die Implementationen dargestellt. Dabei handelt es sich um die Funktionen $W_{poly6}$ in Zeile 59, $\nabla W_{spiky}$ in Zeile 68 und $\nabla^2 W_{visc}$ in Zeile 78.\newline
Die Abbruchfunktionen, wie in \ref{funk:normal}, \ref{funk:gradient2} und \ref{funk:laplace2} zu sehen, wurden dabei durch die Multiplikation mit einer boolesche Variable durchgeführt, welche bei einem Abstand höher als dem Radius dazuführt, dass das Ergebnis 0 wird.

%-------------------------------------------------------------------------------

\subsection{Dichte}\label{dichte}

Die Dichte ist eine Variable die für jeden Partikel individuell berechnet wird. Sie beschreibt die Anzahl der Partikel in unmittelbarer Nähe. Außerdem wird sie bei fast jeder folgenden Berechnung benötigt, da sie als Gewichtung des eingenommenen Volumens dient. 

\begin{equation}\label{funk:skalar}
A_s(r_i) = \sum_j m_j \frac{A_j}{\rho_j} W(r_i-r_j)
\end{equation}
\begin{equation}\label{funk:density}
\rho_i(r_i) = \sum_j m_j \frac{\rho_j}{\rho_j} W(r_i-r_j) = \sum_j m_j  W(r_{i,j})
\end{equation}

Die Dichte, wie in der Gleichung \ref{funk:density} zu sehen, errechnet sich aus der Summe über alle Nachbarn j. Dabei multiplizieren wir die Masse $m_j$ mit der Dichte $\rho_j$ durch die Dichte. Dies wird dann noch mit der Gewichtungsfunktion verrechnet. Die Gleichung ergibt sich aus der Berechnung für Skalaregrößen \ref{funk:skalar} von Müller \cite{muller2003particle}.
\newline\newline
Wie in Abbildung \ref{img:dichte} Zeile 90 zu sehen, ist die Masse der Partikel nicht vom jeweiligen Partikel abhängig. In dem Paper von Ihmsen \cite{ihmsen2014sph} wird eine Formel $m_i = h^3 \rho_0$ für die Masse vorgestellt, diese wird initial durchgeführt und die Masse ist für den Rest der Simulation gleichbleibend. Diese Formel hat sich aber als nicht stabil, in der Implementation, herausgestellt. Deshalb wurde sie als Uniform-Variable implementiert die bei allen Partikel gleich ist. Der Vorteil dieser Implementation ist, dass man die Masse zu beginn oder auch zur Laufzeit verändern kann. Wobei dem ändern während der Laufzeit abzuraten ist, da es zu einem instabilen Verhalten der Simulation führen kann.
\newline
In Zeile 87-89 ist ein If-Abfang eingebaut der es verhindert, dass die Partikel auf sich selbst Einfluss nehmen können. Auf die Begrenzung der Nachbarn, die in die Berechnung eingenommen werden, wird in Abschnitt \ref{besch} eingegangen.
\begin{figure}[H]
	\centering
	\includegraphics[width=1.35\columnwidth]{Bilder/dichte.jpg}
	\caption{Implementation der Dichtefunktion}
	\label{img:dichte}
\end{figure}

%-------------------------------------------------------------------------------

\subsection{Druck}\label{druch}

Der Druckkraft $f^{pressure}$ beschreibt das Abstoßen von Partikeln von einander. Die standardmäßige Berechnung für Skalaregrößen \ref{funk:skalar}, ist aber in diesem Fall nicht symmetrisch und würde zu einen instabilen Simulation führen. Da für Partikel i nur der Druck $p$ des Nachbarpartikel j relevant wäre. Dies würde zu einem unterschiedlichen Druckkraft bei der Berechnung des Druckes zwischen den zwei Partikeln führen. Um dieses Problem zu umgehen stellt Müller \cite{muller2003particle} eine alternative Formel \ref{funk:pressureF} vor, die eine symmetrische Berechnung zwischen den Partikeln ermöglicht. Dabei werden beide Druckwerte addiert, um das Verhältnis aber beizubehalten wird auch die Dichte im Nenner verdoppelt. Zur Gewichtung wird dabei die Gradientenfunktion \ref{funk:gradient2} genutzt und damit der Vektor vom anderen Partikel j weg zeigt wird dieser negiert.
\newline
Zum berechnen der Druckkraft muss aber zunächst der Druck berechnet werden. Die Formel \ref{funk:pressure} von Desbrun \cite{desbrun1996smoothed} diesbezüglich wurde angepasst, indem eine Ruhedichte von der eigentlichen Dichte abgezogen wird. Dabei wird die Ruhedichte $p_0$ als Offset verwendet und hat keinen mathematischen Einfluss auf die Druckkraft \cite{muller2003particle}. Die Variable $k$ beschreibt dabei die Steifheit und bestimmt wie stark sich der Rauch ausdehnt.

\begin{equation}\label{funk:pressure}
p_i = k(\rho - \rho_0)
\end{equation}
\begin{equation}\label{funk:pressureF}
f^{pressure}_i = - \nabla p(r_i) = - \sum_j m_j \frac{p_i+p_j}{2\rho_j} \nabla W(r_{i,j})
\end{equation}

%-------------------------------------------------------------------------------

\subsection{Viskosität}\label{visc}

Ein wichtiger Aspekt der Physik ist auch die Viskosität. Diese beschreibt den Einfluss der Kraft der umliegenden Partikel, dabei haben aber nicht alle Partikel gleich viel Einfluss auf einander. Dies resultiert daraus, dass die Viskosität eine asymmetrische Kraft ist.   Wäre sie jedoch eine symmetrische Kraft würde es dazuführen ,dass viele Partikel die alle gleichzeitig in eine Richtung bewegen, sich ins unendliche beschleunigen würden. Dabei würde es bereits reichen, dass ein einzelner Partikel seine Kraft überträgt, da dieser wie bei einem Dominoeffekt, alle Partikel in seiner Umgebung in seine Bewegungsrichtung beschleunigen würde. Um dies zu umgehen modifiziert Müller \cite{muller2003particle} die SPH-Formel \ref{funk:skalar} indem der Unterschied des Geschwindigkeitsvektor $v$ in Betracht gezogen wird. Dies sorgt dafür, dass ein Partikel mit einem großen Geschwindigkeitsvektor trotzdem noch alle Partikel in seiner Nähe mit sich reißt, aber sich nicht mehr ins unendliche beschleunigen kann.
\newline
Dies lässt den Rauch wirken als würde er sich zusammen ziehen. Das resultiert daraus, dass die Partikel, mit der angepassten Formel, sich auch abbremsen können, da ein schnellerer Partikel beim berechnen der Viskosität mit einem langsamen Partikel einen Viskositätskraft entgegen seiner Bewegungsrichtung erhält. 
\newline
Wie in \ref{funk:visc} wird der Geschwindigkeitsvektor des eigenen Partikel abgezogen. Als Gewichtungsfunktion wird dabei der Laplace\ref{funk:laplace2} der $W_{visc}$\ref{funk:laplace} genutzt.

\begin{equation}\label{funk:visc}
f^{visc}_i  = \mu \sum_j m_j \frac{v_j-v_i}{\rho_j} \nabla^2 W(r_{i,j})
\end{equation}

Die Variable $\mu$ beschreibt die eigentliche Viskosität. $\mu$ ist bei Fluiden wie Honig hoch und bei Rauch sehr gering. In der Implementation hat $\mu$ deshalb einen Wert von $0.25$.

%-------------------------------------------------------------------------------

\subsection{Auftrieb}\label{auftrieb}

Auftrieb ist eine Kraft die abhängig von der Temperatur des Rauches ist. Oftmals wird diese Temperatur statisch implementiert und sich eine Berechnung dieser gespart. Dabei zu beachten ist, dass die Partikel sich bei einer hohen Dichte gegenseitig aufheizen und bei einer niedrigen abkühlen. Um dieses Verhalten umzusetzen wurde die Auftriebsvariante von Ren \cite{ren2016fast} implementiert.
\newline
Zum anpassen der Temperatur der Partikel wurde die Formel \ref{funk:temp} verwendet. Diese betrachtet die Nachbarpartikel und heizt bzw. kühlt die Partikel abhängig der Nachbarn auf oder ab. Bei dieser Formel fehlte aber eine Definition der Funktion Dc, weshalb diese durch die in \ref{imp:temp} ersetzt wurde. Diese multipliziert den Temperatur unterschied mit einer Konstanten $C$ die den Wärmestrom des Rauches beschreibt. $\gamma$ ist dabei nur eine Variable, die positiv und nahe $0$ist, die das Teilen durch $0$ verhindert.
\newline
Die Formel \ref{funk:temp2} beschreibt zudem das Abkühlen von Partikeln die kaum bis keine Nachbarpartikel haben. Dafür wird die Temperatur durch die Zeit geteilt die benötigt wäre um die Temperatur zu halbieren. Welche Partikel dabei betroffen sind wird über die Normale $n_i$ ermittelt, dazu wird die Formel \ref{funk:normale} verwendet. Die Normale wird bei einer geringen Dichte $\rho$ größer und wenn diese einen nutzerdefinierten Schwellwert überschreitet führt dies zur Abkühlung des Partikel. Leider lässt sich diese Formel nur bei einer positiven Temperatur anwenden, welches das Abkühlen von bereits negativen Temperatur verhindert.
\newline
Wenn die Temperatur errechnet wurde lässt diese sich wie in \ref{funk:temp3} berechnen. Dabei beschreibt $b$ einen Up-Vektor und $C_b$ den Auftriebs-Koeffizienten.

\begin{equation}\label{funk:temp}
\frac{\delta T_i}{\delta t}  = \sum_j \frac{m_j}{\rho_i \rho_j} Dc(T_i - T_j) \frac{(r_i-r_j) \cdot \nabla W_{i,j}}{(r_i-r_j)^2 + \gamma^2}
\end{equation}

\begin{equation}\label{funk:normale}
n_i  = \sum_j \frac{m_j}{\rho_j} \nabla W_{i,j}
\end{equation}

\begin{equation}\label{funk:temp2}
\frac{\delta T_i}{\delta t}  = - T_i/D_r
\end{equation}

\begin{equation}\label{funk:temp3}
f^{buoyancy}_i  = C_b T_i b
\end{equation}


\begin{figure}[H]
	\centering
	\includegraphics[width=1.35\columnwidth]{Bilder/thermal.jpg}
	\caption{Implementation der Wärmeleitfähigkeit}
	\label{img:temp}
\end{figure}

%-------------------------------------------------------------------------------

\subsection{Wirbelkraft}\label{wirbel}

Die Wirbelkraft ist die schwierigste zu berechnende Kraft in einem SPH. In dem Paper von Ren \cite{ren2016fast} wird eine beschrieben und ebenfalls die von Macklin \cite{macklin2014unified} erwähnt.
\newline
Ein Bestandteil der Wirbelkraft ist die Wirbelstärke, die sich aus dieser und dem Geschwindigkeitsgradienten, sowie der Normalen und der Gravitation errechnen lässt \ref{funk:wirb}. Bei dem Geschwindigkeitsgradienten ist aber zu beachten, dass dieser eine Jacobi-Matrix der Geschwindigkeit ist und dort eine Matrixmultiplikation mit der Wirbelstärke stattfindet. Um den Gradienten anzunähern wird wie von Macklin \cite{macklin2014unified} empfohlen ein SPH-Gewichtungsfunktion \ref{funk:gradient2} zu nutzen. Diese Formel beschreibt den Abstand des Partikel zu der Oberfläche des Rauches, dabei repräsentiert ein hoher Wert die Oberflächenpartikel und ein kleiner die inneren Partikel.
In der Formel \ref{funk:wirb2} wird dann noch die Wirbelstärke der umliegenden Partikel mit dem Abstandsvektor als Vektorprodukt verrechnet, um einen Vektor zu erhalten der eine Verwirbelung innerhalb des Fluides verursachen soll.  
\begin{equation}\label{funk:wirb}
\frac{\delta \omega_i}{\delta t}  = \omega_i \cdot + \nabla v + \beta(n_i \times g)
\end{equation}

\begin{equation}\label{funk:wirb2}
f^{vortex}_j  = \sum_j (\omega_j \times (r_i -r_j)) W_{i,j}
\end{equation}

Eine Wirbelkraft zu errechnen die Turbulenzen verursacht ist leider nicht gelungen. Diese hatte lediglich die Wirkung die, dass der Rauch langsamer aufgetrieben ist. Das langsame Ausstoßen von Partikeln hatte leider keine positiven Auswirkungen auf die Physik. Dadurch entstanden eher Instabilitäten des Drucks, welcher sich zu beginn anpassen lies, aber dann inkonstant wurde. Eine Anpassung der Variablen führte leider dabei zu keinem Erfolg. Es wurden auch andere Versuche unternommen die Wirbelkraft anzupassen, wie unter anderem die Formel zu modifizieren, welche aber erfolglos blieben.

%-------------------------------------------------------------------------------

\subsection{Update Kräfte}\label{kräfte}

Abschließend werden alle Kräfte zusammen gerechnet und zum Geschwindigkeitsvektor hinzugefügt \ref{funk:update}. Ein Spezialfall dabei ist die Gravitation die mit der Dichte verrechnet wird. Zusätzlich können auch externe Kräfte $ext$ hinzugefügt werden um bestimmte Umwelteinflüsse zu simulieren. Dabei beschränkt es sich lediglich auf einen Vektor der bei allen Partikeln gleichstark wirkt.
\newline

\begin{equation}\label{funk:update}
\frac{\delta v_i}{\delta t}  = f^{pressure}_i + f^{viscosity}_i + f^{buoyancy}_i + f^{vortex}_i + ext + \rho_i g
\end{equation}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.35\columnwidth]{Bilder/external.jpg}
	\caption{Anpassbare Variablen per ImGui}
	\label{img:ext}
\end{figure}
\newpage

%-------------------------------------------------------------------------------

\section{Implementierung}\label{imp}

Bei der Implementierung wurde darauf geachtet, dass das System einfach und schnell anpassbar ist um das Testen zu vereinfachen.
Dazu können einige Parameter während der Laufzeit angepasst werden. Hierfür wurde ImGui \cite{ocornut} verwendet, welches eine UI \ref{img:ext} zur Verfügung stellt um die Parameter anzupassen.
Das Anpassen der Variablen während der Laufzeit kann aber zur Instabilität der Physik führen.
\newline
Da die Implementierung die GPU verwendet muss darauf geachtet werden, dass die angewendeten Verfahren auch parallel berechenbar sind. Da nicht alle Kerne der GPU gleich schnell arbeiten muss es verhindert werden, dass Werte die von anderen Prozessen noch gelesen wird nicht überschrieben werden.
Um dieses Problem zu umgehen wurden zwei identische SSBOs für die Partikel angelegt, welches zwar mehr Speicheraufwand bedeutet, aber bei ca. 65.000 Partikel nur zusätzlich 12 MB beträgt. Bei den zwei SSBOs werden diese im wechsel zum lesen un schreiben genutzt \ref{img:flipflop}. Dadurch besitzt das lesbare SSBO die zuletzt berechneten Daten und schreibt die neuen in das beschreibbare SSBO, hierbei wird aber immer anfangs das beschreibbare zunächst mit dem lesbaren SSBO überschrieben, damit alle Daten aktuell sind.
Es muss dabei aber auch auf eine gerade Anzahl der aufrufe der Compute-Shader geachtet werden, da sonst im Beginn der Update-Schleife aus dem falschen SSBO gelesen wird.
\newline
Für das parallele Schreiben in das gleiche SSBO bedarf es aber wiederum speziellen Operationen, die verhindern, dass mehrere Zugriffe gleichzeitig passieren und eine Variable bearbeiten. Dieses Problem entsteht häufig beim Versuch der Beschleunigung, da dort viele parallele Prozesse der Partikel auf das SSBO des Grids zugreifen.
\newline
OpenGL bietet in GLSL dabei Atomic-Operationen an, diese verhindern das ein anderer Prozess ebenfalls auf die Variable zugreift und diese bearbeitet. Dies entsteht dadurch, dass diese Funktionen zunächst einmal überprüfen ob die Variable bereits bearbeitet wird, falls dies der Fall ist wird solange gewartet bis sie freigegeben wird. Durch viele Prozesse die auf eine Variable zugreifen wollen können dadurch Warteschlangen für diese entstehen, welche in einem Zeitverlust resultiert.

\begin{figure}[H]
	\centering
	\includegraphics[width=1.3\columnwidth]{Bilder/Flipflop.jpg}
	\caption{Partikel SSBOs zum lesen und schreiben}
	\label{img:flipflop}
\end{figure}
\newpage
%-------------------------------------------------------------------------------

\section{Beschleunigung}\label{besch}

Um ein Partikelsystem in einer Engine zu integrieren, muss diese möglichst performant sein, da in einer Engine auch andere Prozesse berechnet werden. Es bestehen mehrere Möglichkeiten ein Partikelsystem zu beschleunigen, eine liegt darin die zu betrachtenden Nachbarpartikel zu begrenzen. Durch die Gewichtungsfunktionen \ref{kernel} werden ohnehin Partikel die außerhalb des Radius $h$ liegen nicht mehr miteinbezogen. Würde man einfach über alle möglichen Nachbarpartikel iterieren, würde ein $O(n^2)$ Aufwand anfallen, hierbei steht n für die Anzahl der Partikel. Dies würde bei 1000 Partikeln ein Aufwand von 1.000.000 Rechenoperationen pro Rechnung bedeuten pro Frame. Dies ließe sich nicht in Echtzeit berechnen geschweige denn in eine Engine integrieren. Deshalb wurden im folgenden Abschnitt die Möglichkeiten, diese Laufzeit zu reduzieren, untersucht und gegenübergestellt.  

%-------------------------------------------------------------------------------

\subsection{gridbasierte Nachbarschaftssuche}\label{nachbar}

Eine Möglichkeit die Laufzeit zu verringern basiert darauf, dass man nur die Nachbarn mit in die Berechnung einbezieht die infrage kommen. Würde man aber alle Partikel miteinander vergleichen und die Nachbarn für einen einzigen Partikel herausfinden und für diese Iteration abspeichern würde dies mit einem immer noch hohem Aufwand so wie einem großen Speicherverbrauch verbunden sein, bei dem nicht klar ist wie viel Speicher benötigt wird, da die Anzahl der Nachbarpartikel nicht bekannt ist.
\newline
Hoetzlein \cite{nvidia} stellt dabei eine auf einem Grid basierte Nachbarschaftssuche da. Diese lässt sich in die folgenden 3 Unterpunkte unterteilen.

\begin{enumerate}
	\item Unterteilen der Welt in gleichgroße Gridbehälter
	\item Hinzufügen der Partikel in die Gridbehälter
	\item Suche der Partikel in den Nachbarbehältern 
\end{enumerate}

Der 1. Punkt wird bereits beim Initialisieren durchgeführt, dabei wird vorher vom Benutzer vorgegeben wie groß das Grid sein soll. Dieser Wert ist zu Laufzeit nicht mehr anpassbar, da das Grid als SSBO angelegt wird. Jedes der Gridbehälter(Grid) besitzt eine eindeutige ID die gleicht mit der gl\_GlobalInvocationID.x in dem Compute-Shader ist. 
\newline
Punkt 2 bedarf einer hohen Menge an Speicherplatz, da davon ausgegangen werden muss, dass im Worst-Case-Szenario sich alle Partikel in einem Grid aufhalten. Welches bei einer Gridgröße von $50x50x50$ und ca. $65.000$ Partikel $8,125$ GB verbrauchen würde rein an Speicherplatz für die Partikel die in einem Grid vorhanden sind. Dabei handelt es sich bei diesen Zahlen um eine Simulation die später als Standardsimulation betrachtet wird.
\newline
Ein Problem dabei ist aber auch, dass die Partikel zunächst zugeordnet werden müssen. Dies erfolgt über die in Abbildung \ref{img:lable} in Zeile 46 zu findende Funktion $cubeID$, welche über die Position des Partikel eine eindeutige GridID ausrechnet. Das hinzufügen der Partikel in die Grids ist je nach Verfahren unterschiedlich und wird genauer in Abschnitt \ref{counting} und \ref{speicher}  erklärt.
\newline
In Punkt 3 handelt es sich lediglich um ein iterieren über alle Partikel in den Nachbarbehältern, da diese bereits stark eingegrenzt wurden und durch die Gewichtungsfunktionen nur die Partikel betrachtet werden die in dem entsprechenden Radius sind.
\newline
In Abbildung \ref{img:grid} sieht man ein vereinfachtes 2D-Grid mit einem Partikel, welcher dem Grid in der Mitte zuzuordnen ist. Bei einem standardmäßigem Radius $h$ von 1, werden alle möglichen Nachbarpartikel die infrage kommen abgedeckt. Hierbei werden alle 9 in 2D oder 27 in 3D Nachbarbehälter betrachtet und über die Partikel in diesen iteriert.

\begin{figure}[H]
	\centering
	\includegraphics[width=1\columnwidth]{Bilder/grid.jpg}
	\caption{Partikel im Grid mit einem Radius von 1}
	\label{img:grid}
\end{figure}

Diese Art der Nachbarschaftssuche besitzt einen Aufwand von $O(n k)$ im optimal Fall, wobei k die Anzahl der Nachbarpartikel ist. Da aber der Speicheraufwand extrem hoch ist kommt diese Art der Nachbarschaftssuche leider nicht in Frage und es wird von Hoetzlein \cite{nvidia} eine alternative Suche mit einem Sortieralgorithmus vorgeschlagen.
\newline
Dabei werden die Partikel den Behältern zugeordnet, diese wiederum Speichern die Anzahl der Partikel aller vorherigen Behälter und wie viele Partikel sie selbst beinhalten. Damit wird dann über einen Sortieralgorithmus bestimmt an welcher Stelle die Partikel zu welchem Grid im Speicher gehören. Dann muss nur noch von einem Grid die erste Speicheradresse, sowie die Anzahl der Partikel abgefragt werden und über diese iteriert werden.
\newline
In Abschnitt \ref{counting} wird genauer auf ein solches Verfahren so wie die Implementation eingegangen.

%-------------------------------------------------------------------------------

\subsection{Speicherverfahren}\label{speicher}

Da beim Speicherverfahren ein großer Aufwand ans Speicherplatz auf der GPU benötigt wird, dieser aber begrenzt ist und deshalb nicht für große Simulationen verwendbar ist, wird eine Begrenzung des genutzten Speicherplatzes angewendet. Heinrich \cite{nvidia2} beschreibt, dass bei der Implementation von Müllers \cite{muller2003particle} Fluidsimulation nur 32 Nachbarnpartikel für eine korrekte Simulation von Nöten sind, die einen Einfluss auf den betrachteten Partikel haben. Da ein ausgeglichener Einfluss auf diesem Partikel herrschen soll, wurden die Nachbarn nicht auf 32 Partikel beschränkt, sondern auf 16 Partikel pro Grid. Dadurch können maximal 432 Partikel in die Berechnungen mit einbezogen werden. Wobei wie man in Abbildung \ref{img:grid} sehen kann nicht alle Grids durch die Gewichtungsfunktionen \ref{kernel} mit einbezogen werden. Im Durchschnitt haben pro Nachbarschaftssuche ca. 138 Nachbarpartikel Einfluss auf die Berechnung.
\newline
Bei der Implementation wurde einfachheitshalber bei den Grids 16 unsigned int Variablen hinzugefügt, die die IDs der Nachbarpartikel beinhaltet.
\newline
Wie in Abbildung \ref{img:Storinglable} zu sehen, werden die zunächst die Zugehörigkeiten der Partikel zu dem Grid berechnet. Daraufhin wird mit der $count$ Variable berechnet, an welche Speicherposition die IDs der Partikel gespeichert wird. Dafür wird wegen den parallelen Prozessen eine Atomic-Funktion genutzt, woraufhin Partikel die einen Wert unter 16 besitzen in dem Grid an der entsprechenden Position gespeichert. Es werden daraufhin bei der Nachbarschaftsbetrachtung nur noch die abgespeicherten IDs abgerufen. 

\begin{figure}[H]
	\centering
	\includegraphics[width=1.3\columnwidth]{Bilder/StoringLable.jpg}
	\caption{Speichern der Partikel-IDs im Grid }
	\label{img:Storinglable}
\end{figure}
\newpage
Diese Form der Nachbarschaftsbetrachtung besitzt in der Theorie einen Aufwand von $O(n k)$. Was aber dabei nicht beachtet wurde ist, dass die Partikel-IDs in den Grids sich sehr stark unterscheiden können, wie in Abbildung \ref{tab:Speicher} zu sehen.
\newline
Durch diesen unsortierten Speicher entstehen scattered reads, diese Art den Speicher auszulesen ist um einiges langsamer als bei einem sortierten Speicher. Dies entsteht durch, dass lesen von Speicheradressen die nicht zusammenhängend sind sondern einen hohen Abstand besitzen.
\newline
Dieses Verfahren ist allerdings noch um einiges schneller als die Brute-Force-Methode.

\begin{figure}[H]
	\centering
	\begin{tabular}{ | c || c | c | c | c | c | c | c | c | c |}
		\hline
		Grid 				&  20 & 16 & 13 & 20 & 20 & 13 & 16 & 18 & 15	\\ \hline
		Speicherposition	&   0 &  1 &  2 &  3 &  4 &  5 &  6 &  7 &  8	\\
		\hline
	\end{tabular}
	\caption{Unsortierter Speicher beim Speicherverfahren}
	\label{tab:Speicher}
\end{figure}

%-------------------------------------------------------------------------------

\subsection{Sortierverfahren}\label{sortieren}
Um das Problem der scattered reads zu beheben, müssen die Speicherpositionen nach dem Grid sortiert werden \ref{tab:Speichersorted}, damit ein Speicherzugriff erfolgen kann der möglichst kompakt ist. Dafür wird aber ein Sortieralgorithmus benötigt. Ein sequentieller Algorithmus würde aufgrund der Architektur der GPU sich dafür nicht eignen, da diese zwar viele Kerne besitzt, die gemeinsam eine große Rechenleistung, aber einzeln nur eine geringe besitzen. Dort wäre es effizienter die Daten wieder auf die CPU zu übertragen und dort sortieren zu lassen.
\begin{figure}[H]
	\centering
	\begin{tabular}{ | c || c | c | c | c | c | c | c | c | c |}
		\hline
		Grid 				&  13 & 13 & 15 & 16 & 16 & 18 & 20 & 20 & 20	\\ \hline
		Speicherposition	&   2 &  5 &  8 &  1 &  6 &  7 &  0 &  3 &  4	\\
		\hline
	\end{tabular}
	\caption{sortierter Speicher nach Sortieralgorithmus}
	\label{tab:Speichersorted}
\end{figure}
Es wird ein paralleler Sortieralgorithmus benötigt, Hoetzlein \cite{nvidia} stellt dabei zwei Sortierverfahren gegenüber. Der erste ist RadixSort, dieser Sortieralgorithmus bezieht sich auf das betrachten der einzelnen Stellen einer Zahl und sortiert anhand dessen. Dadurch, dass jeder Kern eine einzelne Zahl betrachten und diese dann einordnen kann, mach diesen Sortieralgorithmus parallelisierbar.
RadixSort hat einen Aufwand von $O(l n)$, wobei l für die Anzahl der Stellen steht. Laut diesem Aufwand ist er damit schneller als der zweite Algorithmus CountingSort mit einem Aufwand von $O(n log(n))$. Jedoch benötigt laut Hoetzlein \cite{nvidia} RadixSort 15 Kernel calls und CountingSort nur 4 Kernel calls pro Frame. Dadurch ist CountingSort trotz größerem Aufwand der schnellere Algorithmus,auf wessen Theorie und Implementation in Abschnitt \ref{counting}  näher eingegangen wird.

%-------------------------------------------------------------------------------

\subsection{Countigsort}\label{counting}
Countingsort ist ein nicht vergleichsbasierter Algorithmus, dies erlaubt eine parallele Implementation bei der die Laufzeit unabhängig von der Zuordnung des Arrays ist und damit eine festen Aufwand hat.
Die einzelnen Schritte des Sortieralgorithmus erfolgen nach Demaine \cite{counting}.
\newline
Für den Countigsort wird ein Array mit den zu sortierenden Zahlen wie in der Tabelle \ref{tab:Counting1} benötigt, dabei muss die maximale Größe des Wertes im Array bekannt sein.
\newline

\begin{figure}[H]
	\centering
	\begin{tabular}{ | c || c | c | c | c | c |}
		\hline
		Index 				&  0 & 1 & 2 & 3 & 4 \\ \hline
		Wert				&  8 & 2 & 5 & 3 & 5 \\
		\hline
	\end{tabular}
	\caption{Ausgangsarray beim Countingsort}
	\label{tab:Counting1}
\end{figure}

Zunächst werden dann in einem Hilfsarray die Anzahl der vorkommenden Werte bestimmt \ref{tab:Counting2}. Daraufhin wird die Summe aus allen vorherigen Anzahlen bestimmt und in das Hilfsarray geschrieben \ref{tab:Counting3}.
\newline

\begin{figure}[H]
	\centering
	\begin{tabular}{ | c || c | c | c | c | c | c | c | c | c | c |}
		\hline
		Wert 				& 0	&  1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9	\\ \hline
		Anzahl				& 0 &  0 & 1 & 1 & 0 & 2 & 0 & 0 & 1 & 0	\\
		\hline
	\end{tabular}
	\caption{Anzahl der Werte im Hilfsarray}
	\label{tab:Counting2}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{tabular}{ | c || c | c | c | c | c | c | c | c | c | c |}
		\hline
		Wert 				& 0	&  1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9	\\ \hline
		Anzahl				& 0 &  0 & 1 & 2 & 2 & 4 & 4 & 4 & 5 & 5	\\
		\hline
	\end{tabular}
	\caption{Summe der Anzahl der Werte im Hilfsarray}
	\label{tab:Counting3}
\end{figure}

Zu Letzt wird über die Werte des initialen Array iteriert und der Wert an die Anzahl der Summe minus 1 geschrieben, dies beruht darauf, dass die Arrays mit dem Index 0 starten und hat keinen Zusammenhang mit dem folgenden Schritt. Daraufhin wird die Summe der Anzahl bei diesem Wert um 1 verringert, aber bei den folgenden Zahlen nicht angepasst. Dadurch kann eine Zahl mehrfach vorkommen und wird trotzdem richtig einsortiert.
\newline

\begin{figure}[H]
	\centering
	\begin{tabular}{ | c || c | c | c | c | c |}
		\hline
		Index 				&  0 & 1 & 2 & 3 & 4 \\ \hline
		Wert				&  2 & 3 & 5 & 5 & 8 \\
		\hline
	\end{tabular}
	\caption{vollständig sortiertes Array}
	\label{tab:Counting4}
\end{figure}

\newpage
%Implementierung
%-------------------------------------------------------------------------------

Bei der Implementation mussten Anpassungen zwischen dem von Hoetzlein \cite{nvidia} vorgeschlagenen Algorithmus und der Theorie von Demaine \cite{counting}. Diese erfolgten für eine schnellere und stabilere Implementation des Sortieralgorithmus, außerdem liefert Hoetzlein bloß einen groben Aufbau des Algorithmus, welcher als Grundlage des in Abbildung \ref{code:Counting} zu findenden Aufbau diente.
\newline

\begin{figure}[H]
	\centering
	\begin{lstlisting}
computeshader 1
	for all grid i do
		reset grid
	end for
end computeshader 1
computeshader 2
	for all particles i do
		lable Particles to Grid
	end for
end computeshader 2
computeshader 3
	for all grid i do
		init gridBuffer
	end for
end computeshader 3
for log_2(ParticleCount) do
	computeshader 4
		for all grid i do
			calculate PrefixSum
		end for
	end computeshader 4
	computeshader 5
		for all grid i do
			update gridBuffer
		end for
	end computeshader 5
end for
computeshader 6
	for all particles i do
		rearrange Particles
	end for
end computeshader 6
	\end{lstlisting}
	\caption{Aufbau des Implementierten Countingsort}
	\label{code:Counting}
\end{figure}
\newpage

Der Sortieralgorithmus beginnt mit dem zurücksetzen des Grid-SSBO \ref{img:GridStruct}. Dies dient dazu, dass die  Berechnung des vorherigen Frames keinen Einfluss hat. Dabei werden alle Variablen bis auf die $id$ zurückgesetzt, wobei die $id$ und der $previousSortOutPut$ Füllervariablen sind um die 16 Byte zu erreichen, sie haben aber noch einen Mehrwert im Debugging.

\begin{figure}[H]
	\centering
	\includegraphics[width=1.3\columnwidth]{Bilder/GridStruct.jpg}
	\caption{SSBO-Struct des Grids}
	\label{img:GridStruct}
\end{figure}

Im Folgenden wird wie in Abbildung \ref{img:lable} in Zeile 60 zu sehen die Anzahl der Partikel in einem Grid gespeichtert, die Zugehörigkeit zum Grid wird über die CubeID-Funktion ermittelt. Eine atomicAdd-Funktion wird dabei durchgeführt und es wird der Wert $grid[temp].particlesInGrid$ um 1 erhöht. In $outParticle[id].memoryPosition$ wird der Wert vor der Addition gespeichert und dieser sagt aus als wievielter sich dieser Partikel im Grid registriert hat. Die Abwandelung mit dieser Variable spart beim $rearrange Particles$-Schritt kostbare Laufzeit.

\begin{figure}[H]
	\centering
	\includegraphics[width=1.3\columnwidth]{Bilder/lable.jpg}
	\caption{registrieren der Partikel im Grid mit CubeID-Funktion }
	\label{img:lable}
\end{figure}

Zum Berechnen der Prefixsum wird der parallele Scan von Nav\"{i}e nach Harris \cite{harris2007parallel} implementiert. Dieser berechnet die Prefixsum über die Summe der bisherigen Anzahl der $i - 2^d$ Nachbarn, wobei $d = 0$ to $log_2(n)-1$.

\begin{figure}[H]
	\centering
	\includegraphics[width=1.0\columnwidth]{Bilder/PrefixSum.jpg}
	\caption{paralleler Prefixsum Scan von Nav\"{i}e nach Harris \cite{harris2007parallel}}
	\label{img:prefixsum}
\end{figure}

Um den ersten Schritt zu vereinfachen und keinen Zugriff auf Variablen zu haben, die überschrieben werden könnten, wird der Algorithmus damit initialisiert, dass die Anzahl der Partikel die sich im Grid befinden in den $currentSortOutPut$ sowie in den Gridbuffer geschrieben wird.
\newline
Der Gridbuffer dient in dem Fall als temporärer Buffer, der bloß eine Float-Variable speichert, damit nicht gleichzeitig aus einem Buffer die gleiche Variable gelesen und beschrieben wird.
Dafür werden die ComputeShader zu Berechnung der Prefixsum und zum updaten des Gridbuffers im wechsel $log_2(Particleanzahl)-1$ durchgeführt. Bei der Prefixsum wird aus dem Gridbuffer die aktuelle Summe plus die Summe des $i - 2^d$ Nachbarn addiert und in dem $currentSortOutPut$ des Grid-SSBOs gespeichert. Daraufhin wird der Gridbuffer aktualisiert und es wird die Summe die in der $currentSortOutPut$ Variable steht übertragen.
\newline
Im letzten Schritt müssen die Partikel nur noch neu angeordnet werden. Dies müsste nach dem Algorithmus für jedes Grid sequentiell ablaufen, damit sich die Partikel nacheinander an die richtige Position schreiben. Dies entspricht dem Schritt von \ref{tab:Counting3} zu \ref{tab:Counting4}.
\newline
Um diesen sequentiellen Prozess zum umgehen wurde aber im Vorhinein bereits in der $outParticle[id].memoryPosition$ die Position des Partikels im Grid bestimmt. Deshalb können die Partikel wie in \ref{img:rearrange} zu sehen, sich bloß an die entsprechende Speicherstelle schreiben. Dadurch befinden sich nun alle Partikel die in einem Grid sind in aufeinanderfolgenden Speicherplätzen und verhindert damit scattered reads.

\begin{figure}[H]
	\centering
	\includegraphics[width=1.3\columnwidth]{Bilder/rearrange.jpg}
	\caption{umorganisieren der Partikel im Speicher}
	\label{img:rearrange}
\end{figure}

Das Aufrufen der Nachbarpartikel erfolgt daraufhin wie zum Beispiel bei der Normalenberechnung \ref{img:normal}. Dabei wird zunächst die $id$ des Nachbargrids über die $CubeID$-Funktion ermittelt. Daraufhin wird der $currentSortOutPut$ des Nachbargrids, welcher dem ersten Partikel in dem Grid entspricht, als initial Wert der For-Schleife genommen. Diese läuft bis die Summe des $currentSortOutPut$ plus die $particlesinGrid$ erreicht worden sind oder eine andere Abbruchbedingung eintritt.

\begin{figure}[H]
	\centering
	\includegraphics[width=1.3\columnwidth]{Bilder/normal.jpg}
	\caption{Berechnung der Normalen einen Partikel}
	\label{img:normal}
\end{figure}

%-------------------------------------------------------------------------------

\subsection{Vergleich}\label{vergleich}

Die beiden Beschleunigungsverfahren bieten auf Kosten von Speicherplatz oder Laufzeit für das Sortieren eine sehr starke Verkürzung der Laufzeit. Im folgenden werden beide Beschleunigungsverfahren gegenübergestellt und mit einander auf Vor- und Nachteile untersucht.
\newline
Damit bei beiden Verfahren über gleich viele Partikel iteriert wird und dies damit keinen Einfluss auf die Beschleunigung hat wurde der Countingsort ebenfalls auf 16 Partikel pro Grid beschränkt \ref{img:normal}. Als Standardwerte für die Partikelanzahl wird $65.536$ und für die Gridgröße $50x50x50$ angesehen, welche bei speziellen Tests für die Partikel oder das Grid dann variieren können.
\newline
Die Tests wurden auf einem Desktop-Pc mit einer Intel(R) Core(TM) i5-9600k CPU @ 4.0 GHz und einer Nvidia GeForece GTX 1660 Ti Grafikkarte durchgeführt. Bei den Tests wurden die Durchschnittswerte von 20s Laufzeit pro Simulation, die jeder 10 mal wiederholt wurden, ausgewertet. Bei den zeitlichen Angaben handelt es sich um Millisekunden pro Frame.
\newline
Beim Vergleich der Sortieralgorithmen bei steigender Partikelanzahl \ref{tab:particle} haben beide eine ähnliche Berechnungsdauer bei einer niedrigen Anzahl, dabei ist aber der Countingsort bereits ein wenig schneller. Besonders bemerkbar macht sich der Unterschied bei hoher Partikelanzahl bei dem das Speicherverfahren fast die doppelte Laufzeit pro Frame besitzt. Dies ist ganz klar auf die scattered reads zurückzuführen, die das Speicherverfahren, trotz weniger Kernal calls, erheblich verlangsamen.
\newline

\begin{figure}[H]
	\centering
	\begin{tabular}{ | c || c | c | c | c | c | c | c | c |}
		\hline
		Partikel			&  8.912 & 16.384 & 32.768 & 65.536 & 131.072 & 262.144 & 524.288 & 1.048.576	\\ \hline
		Countingsort														\\ \hline
		Laufzeit(ms)		&   0,72 &  1,27 &  2,13 &  4,12 &  12,71 &  27,81 &  56,72 &  142,56		 	\\ \hline
		
		Speicher															\\ \hline
		Laufzeit(ms)		&   0,9 &  1,88 &  3,69 &  7,34 &  15,15 &  38,71 &  107.45 &  270,65	\\
		\hline
	\end{tabular}
	\caption{Laufzeit in Relation zur Partikelanzahl}
	\label{tab:particle}
\end{figure}

Einen Einfluss auf die Laufzeit hat auch die Griddimension, wobei dieser sehr viel geringer ausfällt als die der Partikelanzahl. Wie in Abbildung \ref{tab:Grid} zu sehen, ist auch hier der Countingsort schneller und bei diesem haben die Griddimensionen auch weniger Einfluss auf die Laufzeit, als beim Speicherverfahren. Beim Speicherverfahren steigt die Laufzeit stärker an, obwohl dieser anstieg sich nicht signifikant von dem des Countingsort unterscheidet.
\newline

\begin{figure}[H]
	\centering
	\begin{tabular}{ | c || c | c | c | c | c | c | c | c | c |}
		\hline
		Partikel			&  20 & 30 & 40 & 50 & 60 & 70 & 80 & 90 & 100	\\ \hline
		Countingsort														\\ \hline
		Laufzeit(ms)		&   5,85 &  4,43 &  3,92 &  4,04 &  4,27 &  4,54 &  4,85 &  5,37 &	6,36	 	\\ \hline
		
		Speicher															\\ \hline
		Laufzeit(ms)		&   7,4 &  7,04 &  7,14 &  7,45 &  8,47 &  9,29 &  9.54 &  9,84 & 10,41	\\
		\hline
	\end{tabular}
	\caption{Laufzeit in Relation zur den Griddimensionen}
	\label{tab:Grid}
\end{figure}

Das Sinken und anschließende Steigen aus Abbildung \ref{tab:Grid} lässt sich durch das stärkere verteilen der Partikel erklären, da sich in einem kleineren Raum mehr Partikel in einem Grid befinden und sich dadurch mehr atomicAdd-Funktionen bei den einzelnen Grids stauen.

\begin{figure}[H]
	\centering
	\begin{tikzpicture}
		\begin{axis}[width=1.0\textwidth,height=0.5\textheight]
		\addplot[smooth,mark=*,blue]
		coordinates {
			(20,30.158) (30,30.656) (40,31.376) (50,32.569) (60,34.345) (70,36.826) (80,40.126) (90,44.365) (100,49.658)
		};
		\addlegendentry{Countingsort}
		\addplot[smooth,color=red,mark=x]
		coordinates {
			(20,26.681) (30,28.237) (40,31.271) (50,36.276) (60,43.740) (70,54.158) (80,68.021) (90,85.823) (100,108.053)
		};
		\addlegendentry{Speicher}
		\end{axis}
	\end{tikzpicture}
	\caption{Speicherverbrauch in Kb auf der Y-Achse und Griddimensionen auf der X-Achse }
	\label{dia:speicher}
\end{figure}

Da der Speicherplatz der Grafikkarte nicht unbegrenzt ist, lohnt es sich ebenfalls einen Blick auf diesen zu werfen in Verbindung mit den Griddimensionen, da diese sich bei den Sortieralgorithmen im nutzenden Speicher unterscheiden \ref{dia:speicher}.
\newline
Zunächst hat das Speicherverfahren einen geringeren Verbrauch, welcher daraus resultiert, dass für den Countingsort neben dem Grid-SSBO noch der temporäre Gridbuffer als SSBO existiert. Doch Beim Speicherverfahren steigt der benötigte Speicherplatz sehr viel stärker an als beim Countigsort. Bei diesem ist nur ein geringer anstieg zu verzeichnen.

%-------------------------------------------------------------------------------

\section{Ergebnis}\label{ergebnis}

In der Studienarbeit wurde gezeigt, dass eine Rauchsimulation die nur auf einem Partikelsystem basiert schwer in der Realisierung von Wirbelkräften ist. Diese lassen sich nicht über simple Partikelinteraktionen simulieren und bedürfen für eine realistische Simulation eine Erweiterung in Form eines Vektorfeldes oder einer ähnlichen Technik. Eine eigen kreierte Physik zu Realisierung von Wirbelkräften in einem Partikelsystem bedarf einer Einarbeitung und Umsetzung in dieser Thematik die zu umfangreich Zeitaufwändig gewesen wäre.
\newline
Die Simulation kann durch das Anpassen der Variablen ebenfalls für andere Simulationen genutzt werden, wie zum Beispiel Wasser oder andere Flüssigkeiten deren Physik rein auf der Partikelinteraktion in einem Partikelsystem basieren kann.
\newline
Die Beschleunigung des Systems war besonders erfolgreich. Die Implementation beider Beschleunigungsverfahren erzielte ihre Vorgabe, sodass das Partikelsystem in Echtzeit simuliert werden konnte. Dabei erwies sich der Countingsort mit den persönlichen Anpassungen als performanter bei einer hohen Partikelanzahl, sowie effizienter im Speicherverbrauch als das Speicherverfahren. Außerdem besitzt der Countingsort eine stabilere Laufzeit als das Speicherverfahren, da dieses durch die scattered reads teilweise sehr starke Schwankungen in der Performance aufweisen.
\newline
Das Integrieren der Simulation in eine Engine  wäre deshalb mit dem Countingsort möglich und empfehlenswert.
\newline
Die vorliegende Fluidsimulation bietet viele Möglichkeiten zur Erweiterung. Eine angedachte wäre die Realisierung einer Technik zur besseren Berechnung der Wirbelkraft, da diese einen großen optischen Einfluss auf die Simulation hat.
\newline
Außerdem wurden bisher nur Point-Sprites gerendert, welche zwar einen Vorteil für die Berechnung bieten, aber nicht besonders optisch ansprechend sind. Deshalb würde sich hier ein realistisches Rendern der Partikel anbieten.
\newline
Die Performance ebenfalls noch ausbaufähig, hier sollte man noch andere Beschleunigungsverfahren in Betracht ziehen und gegeneinander abwägen. Außerdem sollten weitere Anpassungen beim Countingsort in Zukunft sich positiv auf dessen Beschleunigung des Systems auswirken.
\newline
In Abbildung \ref{img:particle1} und \ref{img:particle2} sieht man die Ausbreitung der Partikel welcher durch den Druck und die Viskosität entsteht. Außerdem steigen die Partikel durch eine hohe Temperatur auf, welche in Abbildung \ref{img:particle3} abkühlt und zum absinken der gesamten Partikel führt.

%-------------------------------------------------------------------------------

\begin{figure}[H]
	\subfigure{\includegraphics[width=0.49\textwidth]{Bilder/1.jpg}}
	\subfigure{\includegraphics[width=0.49\textwidth]{Bilder/2.jpg}}
	\caption{Aufstieg und Ausbreitung der Partikel}
	\label{img:particle1}
\end{figure}

\begin{figure}[H]
	\subfigure{\includegraphics[width=0.49\textwidth]{Bilder/3.jpg}}
	\subfigure{\includegraphics[width=0.49\textwidth]{Bilder/4.jpg}}
	\caption{Ausbreitung der Partikel}
		\label{img:particle2}
\end{figure}

\begin{figure}[H]
	\subfigure{\includegraphics[width=0.49\textwidth]{Bilder/5.jpg}}
	\subfigure{\includegraphics[width=0.49\textwidth]{Bilder/6.jpg}}
	\caption{Absinken der Partikel nach einiger Zeit}
		\label{img:particle3}
\end{figure}

\newpage
\listoffigures
\newpage
\bibliography{lib}

\end{document}